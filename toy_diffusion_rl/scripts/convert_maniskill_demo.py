#!/usr/bin/env python3
"""
Convert ManiSkill3 Demo Trajectory to Training Dataset Format.

This script converts ManiSkill3 replay_trajectory output (which contains per-trajectory
data with obs, actions, rewards, etc.) to the flat HDF5 format compatible with
ManiSkillOfflineDataset in dataset_loader.py.

Features:
- Reads ManiSkill3 trajectory format (traj_0, traj_1, ...)
- Extracts state (qpos, qvel only - robot proprioceptive state)
- Extracts RGB images and resizes to target size
- Computes next_obs and next_images
- Saves in format compatible with dataset_loader.py

Usage:
    python scripts/convert_maniskill_demo.py \
        --input_path ~/.maniskill/demos/PegInsertionSide-v1/motionplanning/trajectory.state_dict+rgb.pd_joint_pos.gpu.h5 \
        --output_path data/peg_insertion_side_1k.h5 \
        --image_size 128

Note:
    Input trajectory must be generated by ManiSkill3's replay_trajectory with:
    - obs_mode: state_dict+rgb (contains agent/extra dicts and sensor_data)
    - --record-rewards enabled
    - --save-traj enabled
"""

import warnings
warnings.filterwarnings("ignore", message=".*pynvml.*deprecated.*", category=FutureWarning)
warnings.filterwarnings("ignore", message=".*pkg_resources is deprecated.*", category=UserWarning)

import argparse
import os
import sys
import h5py
import numpy as np
import json
import cv2
from pathlib import Path
from tqdm import tqdm
from typing import Dict, List, Tuple, Optional


def flatten_agent_state(obs_group: h5py.Group, timestep: int) -> np.ndarray:
    """Extract and flatten robot proprioceptive state (qpos, qvel) from observation.
    
    Only includes robot arm state, not task-specific information like object poses.
    This ensures consistent state dimension across different tasks.
    
    Args:
        obs_group: HDF5 group containing observation data
        timestep: Timestep index to extract
    
    Returns:
        Flattened state array containing [qpos, qvel]
    """
    parts = []
    
    # Extract agent state (robot proprioceptive)
    if "agent" in obs_group:
        agent_group = obs_group["agent"]
        
        # qpos - joint positions
        if "qpos" in agent_group:
            qpos = agent_group["qpos"][timestep]
            parts.append(qpos.flatten())
        
        # qvel - joint velocities
        if "qvel" in agent_group:
            qvel = agent_group["qvel"][timestep]
            parts.append(qvel.flatten())
    
    if not parts:
        raise ValueError("No agent state found in observation")
    
    return np.concatenate(parts).astype(np.float32)


def extract_rgb_image(obs_group: h5py.Group, timestep: int, image_size: int = 128) -> np.ndarray:
    """Extract and resize RGB image from observation.
    
    Args:
        obs_group: HDF5 group containing observation data
        timestep: Timestep index to extract
        image_size: Target image size (square)
    
    Returns:
        RGB image as uint8 array of shape (H, W, 3)
    """
    rgb = None
    
    # Try sensor_data first (standard ManiSkill3 format)
    if "sensor_data" in obs_group:
        sensor_data = obs_group["sensor_data"]
        # Find first camera with rgb
        for cam_name in sensor_data.keys():
            cam_group = sensor_data[cam_name]
            if "rgb" in cam_group:
                rgb = cam_group["rgb"][timestep]
                break
    
    if rgb is None:
        raise ValueError("No RGB data found in observation")
    
    # Ensure uint8
    if rgb.dtype != np.uint8:
        if rgb.max() <= 1.0:
            rgb = (rgb * 255).astype(np.uint8)
        else:
            rgb = rgb.astype(np.uint8)
    
    # Resize if needed
    if rgb.shape[0] != image_size or rgb.shape[1] != image_size:
        rgb = cv2.resize(rgb, (image_size, image_size), interpolation=cv2.INTER_AREA)
    
    return rgb


def convert_trajectory(
    input_path: str,
    output_path: str,
    image_size: int = 128,
    max_episodes: Optional[int] = None,
    max_episode_length: Optional[int] = None,
    min_episode_length: Optional[int] = None,
    task: str = "PegInsertionSide-v1",
    verbose: bool = True,
) -> Dict:
    """Convert ManiSkill3 trajectory file to training dataset format.
    
    Args:
        input_path: Path to ManiSkill3 trajectory HDF5 file
        output_path: Path to output HDF5 file
        image_size: Target image size for resizing
        max_episodes: Maximum number of episodes to convert (None for all)
        task: Task name for metadata
        verbose: Whether to print progress
    
    Returns:
        Statistics dictionary with conversion results
    """
    if verbose:
        print(f"Loading trajectory file: {input_path}")
    
    # Detect control mode from filename
    # Format: trajectory.{obs_mode}.{control_mode}.{backend}.h5
    input_filename = os.path.basename(input_path)
    parts = input_filename.replace(".h5", "").split(".")
    if len(parts) >= 3:
        control_mode = parts[-2]  # e.g., pd_joint_pos
    else:
        control_mode = "unknown"
    
    if verbose:
        print(f"Detected control mode: {control_mode}")
    
    # Read input file
    with h5py.File(input_path, "r") as f_in:
        # Get trajectory keys
        traj_keys = sorted([k for k in f_in.keys() if k.startswith("traj_")],
                          key=lambda x: int(x.split("_")[1]))
        
        if max_episodes is not None:
            traj_keys = traj_keys[:max_episodes]
        
        total_episodes = len(traj_keys)
        
        if verbose:
            print(f"Found {total_episodes} trajectories to convert")
        
        # Collect all data
        all_obs = []
        all_next_obs = []
        all_images = []
        all_next_images = []
        all_actions = []
        all_rewards = []
        all_dones = []
        all_episode_ids = []
        all_timesteps = []
        
        successful_episodes = 0
        failed_episodes = 0
        
        pbar = tqdm(traj_keys, desc="Converting trajectories") if verbose else traj_keys
        
        filtered_by_length = 0
        
        for traj_key in pbar:
            traj = f_in[traj_key]
            episode_id = int(traj_key.split("_")[1])
            
            try:
                # Get trajectory length from actions
                actions = traj["actions"][:]
                T = len(actions)
                
                # Get success flag to find true task completion
                # ManiSkill3 parallel replay may have corrupted terminated/truncated
                # where some envs show done=True from step 0
                success = traj["success"][:] if "success" in traj else np.zeros(T, dtype=bool)
                
                # Skip trajectories that start with success=True (corrupted)
                if success[0]:
                    failed_episodes += 1
                    continue
                
                # Find first success and truncate episode there
                success_indices = np.where(success)[0]
                if len(success_indices) > 0:
                    first_success_idx = success_indices[0]
                    # Keep data up to and including first success
                    T_effective = first_success_idx + 1
                else:
                    # No success found - skip this trajectory (failed demo)
                    failed_episodes += 1
                    continue
                
                # Apply length filter after truncation
                if min_episode_length is not None and T_effective < min_episode_length:
                    filtered_by_length += 1
                    continue
                if max_episode_length is not None and T_effective > max_episode_length:
                    filtered_by_length += 1
                    continue
                
                # Get rewards
                if "rewards" in traj:
                    rewards = traj["rewards"][:]
                else:
                    # Fallback: zeros
                    rewards = np.zeros(T, dtype=np.float32)
                
                # Get observations (T+1 timesteps)
                obs_group = traj["obs"]
                
                for t in range(T_effective):
                    # Current observation (at timestep t)
                    state = flatten_agent_state(obs_group, t)
                    image = extract_rgb_image(obs_group, t, image_size)
                    
                    # Next observation (at timestep t+1)
                    next_state = flatten_agent_state(obs_group, t + 1)
                    next_image = extract_rgb_image(obs_group, t + 1, image_size)
                    
                    all_obs.append(state)
                    all_next_obs.append(next_state)
                    all_images.append(image)
                    all_next_images.append(next_image)
                    all_actions.append(actions[t])
                    all_rewards.append(rewards[t])
                    # Only mark done at the last step of truncated episode
                    all_dones.append(t == T_effective - 1)
                    all_episode_ids.append(episode_id)
                    all_timesteps.append(t)
                
                successful_episodes += 1
                
            except Exception as e:
                if verbose:
                    print(f"\nWarning: Failed to convert {traj_key}: {e}")
                failed_episodes += 1
                continue
    
    # Convert to numpy arrays
    if verbose:
        print(f"\nConverting {len(all_obs)} transitions to arrays...")
    
    obs_arr = np.array(all_obs, dtype=np.float32)
    next_obs_arr = np.array(all_next_obs, dtype=np.float32)
    images_arr = np.array(all_images, dtype=np.uint8)
    next_images_arr = np.array(all_next_images, dtype=np.uint8)
    actions_arr = np.array(all_actions, dtype=np.float32)
    rewards_arr = np.array(all_rewards, dtype=np.float32)
    dones_arr = np.array(all_dones, dtype=bool)
    episode_ids_arr = np.array(all_episode_ids, dtype=np.int32)
    timesteps_arr = np.array(all_timesteps, dtype=np.int32)
    
    # Sort by episode_id then timestep
    if verbose:
        print("Sorting data by episode_id and timestep...")
    sort_indices = np.lexsort((timesteps_arr, episode_ids_arr))
    
    obs_arr = obs_arr[sort_indices]
    next_obs_arr = next_obs_arr[sort_indices]
    images_arr = images_arr[sort_indices]
    next_images_arr = next_images_arr[sort_indices]
    actions_arr = actions_arr[sort_indices]
    rewards_arr = rewards_arr[sort_indices]
    dones_arr = dones_arr[sort_indices]
    episode_ids_arr = episode_ids_arr[sort_indices]
    timesteps_arr = timesteps_arr[sort_indices]
    
    # Renumber episode_ids to be consecutive starting from 0
    unique_episodes = np.unique(episode_ids_arr)
    episode_map = {old: new for new, old in enumerate(unique_episodes)}
    episode_ids_arr = np.array([episode_map[ep] for ep in episode_ids_arr], dtype=np.int32)
    
    # Save to output file
    if verbose:
        print(f"Saving to: {output_path}")
    
    os.makedirs(os.path.dirname(output_path) or ".", exist_ok=True)
    
    with h5py.File(output_path, "w") as f_out:
        f_out.create_dataset("obs", data=obs_arr, compression="gzip")
        f_out.create_dataset("next_obs", data=next_obs_arr, compression="gzip")
        f_out.create_dataset("images", data=images_arr, compression="gzip")
        f_out.create_dataset("next_images", data=next_images_arr, compression="gzip")
        f_out.create_dataset("actions", data=actions_arr, compression="gzip")
        f_out.create_dataset("rewards", data=rewards_arr, compression="gzip")
        f_out.create_dataset("dones", data=dones_arr, compression="gzip")
        f_out.create_dataset("episode_ids", data=episode_ids_arr, compression="gzip")
        f_out.create_dataset("timesteps", data=timesteps_arr, compression="gzip")
        
        # Metadata
        metadata = {
            "obs_mode": "state_image",
            "num_episodes": len(unique_episodes),
            "num_transitions": len(actions_arr),
            "task": task,
            "control_mode": control_mode,
            "image_size": image_size,
            "state_keys": ["agent/qpos", "agent/qvel"],
        }
        f_out.attrs["metadata"] = json.dumps(metadata)
        f_out.attrs["obs_mode"] = "state_image"
        f_out.attrs["num_episodes"] = len(unique_episodes)
        f_out.attrs["num_transitions"] = len(actions_arr)
        f_out.attrs["task"] = task
        f_out.attrs["control_mode"] = control_mode
    
    # Statistics
    stats = {
        "total_episodes": total_episodes,
        "successful_episodes": successful_episodes,
        "failed_episodes": failed_episodes,
        "filtered_by_length": filtered_by_length,
        "replay_success_rate": successful_episodes / total_episodes if total_episodes > 0 else 0,
        "num_transitions": len(actions_arr),
        "state_dim": obs_arr.shape[1],
        "action_dim": actions_arr.shape[1],
        "image_shape": images_arr.shape[1:],
        "reward_range": [float(rewards_arr.min()), float(rewards_arr.max())],
    }
    
    if verbose:
        print("\n" + "=" * 60)
        print("Conversion Statistics")
        print("=" * 60)
        print(f"Total episodes in input: {stats['total_episodes']}")
        print(f"Successfully converted: {stats['successful_episodes']}")
        print(f"Filtered by length: {stats['filtered_by_length']}")
        print(f"Failed conversions: {stats['failed_episodes']}")
        if min_episode_length is not None or max_episode_length is not None:
            print(f"Episode length filter: min={min_episode_length}, max={max_episode_length}")
        print(f"Failed conversions: {stats['failed_episodes']}")
        print(f"Replay success rate: {stats['replay_success_rate']*100:.1f}%")
        print(f"Total transitions: {stats['num_transitions']}")
        print(f"State dimension: {stats['state_dim']}")
        print(f"Action dimension: {stats['action_dim']}")
        print(f"Image shape: {stats['image_shape']}")
        print(f"Reward range: {stats['reward_range']}")
        print("=" * 60)
    
    return stats


def main():
    parser = argparse.ArgumentParser(
        description="Convert ManiSkill3 trajectory to training dataset format"
    )
    parser.add_argument(
        "--input_path",
        type=str,
        required=True,
        help="Path to ManiSkill3 trajectory HDF5 file (output of replay_trajectory)"
    )
    parser.add_argument(
        "--output_path",
        type=str,
        required=True,
        help="Path to output HDF5 file"
    )
    parser.add_argument(
        "--image_size",
        type=int,
        default=128,
        help="Target image size (default: 128)"
    )
    parser.add_argument(
        "--max_episodes",
        type=int,
        default=None,
        help="Maximum number of episodes to convert (default: all)"
    )
    parser.add_argument(
        "--min_episode_length",
        type=int,
        default=None,
        help="Minimum episode length to include (default: no limit)"
    )
    parser.add_argument(
        "--max_episode_length",
        type=int,
        default=None,
        help="Maximum episode length to include (default: no limit)"
    )
    parser.add_argument(
        "--task",
        type=str,
        default="PegInsertionSide-v1",
        help="Task name for metadata (default: PegInsertionSide-v1)"
    )
    parser.add_argument(
        "--quiet",
        action="store_true",
        help="Suppress progress output"
    )
    
    args = parser.parse_args()
    
    if not os.path.exists(args.input_path):
        print(f"Error: Input file not found: {args.input_path}")
        sys.exit(1)
    
    stats = convert_trajectory(
        input_path=args.input_path,
        output_path=args.output_path,
        image_size=args.image_size,
        max_episodes=args.max_episodes,
        min_episode_length=args.min_episode_length,
        max_episode_length=args.max_episode_length,
        task=args.task,
        verbose=not args.quiet,
    )
    
    print("\nDone!")


if __name__ == "__main__":
    main()
